{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import torchvision.models as models\nfrom PIL import Image\nimport pandas as pd\nimport torch\nimport os\nimport time\nfrom torchvision import transforms\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport requests\nimport zipfile\n\ntorch.manual_seed(0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# DOWNLOAD DATA\n\nurls = [\n    \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\",\n    \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\"\n]\n\nfor url in urls:\n    print(f\"[INFO] Downloading from: {url}\")\n    r = requests.get(url, allow_redirects=True)\n    open(url.split('/')[-1], 'wb').write(r.content)\n    print(f\"[INFO] Downloaded {url.split('/')[-1]} successfully.\")\n\nfile_names = [\"Positive_tensors.zip\", \"Negative_tensors.zip\"]\n\nfor file_name in file_names:\n    print(f\"[INFO] Extracting {file_name} ...\")\n    with zipfile.ZipFile(file_name, 'r') as zip_ref:\n        zip_ref.extractall('.')\n    print(f\"[INFO] Extracted {file_name} successfully.\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Define Dataset Class\nclass Dataset(Dataset):\n    def __init__(self, transform=None, train=True):\n        directory = \"C:\\\\Users\\\\marcnune\\\\Documents\\\\GitHub\\\\-crack-detector-resnet-pytorch\"\n        positive = \"Positive_tensors\"\n        negative = 'Negative_tensors'\n\n        positive_file_path = os.path.join(directory, positive)\n        negative_file_path = os.path.join(directory, negative)\n        positive_files = [os.path.join(positive_file_path, file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n        negative_files = [os.path.join(negative_file_path, file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n        \n        number_of_samples = len(positive_files) + len(negative_files)\n        self.all_files = [None] * number_of_samples\n        self.all_files[::2] = positive_files\n        self.all_files[1::2] = negative_files\n        \n        self.transform = transform\n        self.Y = torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2] = 1\n        self.Y[1::2] = 0\n        \n        if train:\n            self.all_files = self.all_files[0:30000]\n            self.Y = self.Y[0:30000]\n            self.len = len(self.all_files)\n        else:\n            self.all_files = self.all_files[30000:]\n            self.Y = self.Y[30000:]\n            self.len = len(self.all_files)\n\n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, idx):\n        image = torch.load(self.all_files[idx])\n        y = self.Y[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, y",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Initialize Train and Validation Dataset\ntrain_dataset = Dataset(train=True)\nvalidation_dataset = Dataset(train=False)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Load and Modify Pre-Trained Model\nprint(\"[INFO] Loading pre-trained ResNet18...\")\nmodel = models.resnet18(pretrained=True)\n\n# Set parameters to non-trainable\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Modify the output layer\nmodel.fc = nn.Linear(512, 2)  # As we have two classes: positive and negative\nprint(\"[INFO] Modified the last layer for binary classification.\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Setup Loss Function, DataLoaders, and Optimizer\ncriterion = nn.CrossEntropyLoss()\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=100)\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=100)\noptimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr=0.001)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Training loop\nn_epochs = 2\nloss_list = []\naccuracy_list = []\nN_test = len(validation_dataset)\nstart_time = time.time()\n\nfor epoch in range(n_epochs):\n    for x, y in train_loader:\n        model.train()\n        optimizer.zero_grad()\n        z = model(x)\n        loss = criterion(z, y)\n        loss.backward()\n        optimizer.step()\n        loss_list.append(loss.data)\n    \n    correct = 0\n    for x_test, y_test in validation_loader:\n        model.eval()\n        z = model(x_test)\n        _, yhat = torch.max(z.data, 1)\n        correct += (yhat == y_test).sum().item()\n    accuracy = correct / N_test",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Plotting Results\nprint(\"Accuracy: \", accuracy)\nplt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Displaying Misclassified Samples\nmisclassified_samples = []\nfor x, y in validation_loader:\n    z = model(x)\n    _, yhat = torch.max(z.data, 1)\n    misclassified_indices = torch.where(yhat != y)[0]\n    misclassified_samples += [(x[i], yhat[i], y[i]) for i in misclassified_indices]\n\nfor index, (img, pred, actual) in enumerate(misclassified_samples[:4]):\n    print(f\"Sample {index + 1} - Predicted: {pred}, Actual: {actual}\")\n    plt.imshow(img[0], cmap='gray')\n    plt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}